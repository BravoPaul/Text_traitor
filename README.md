
项目简介：
这个project的目的是通过作者写的一段英语段落来判断作者的国籍。
因为不同国家的人在使用英语的时候会表现出不一样的风格，例如某些单词的使用，短语的使用，标点符号的使用，个别单词的频率，地名等。这些都会有细微的差别。所以这个project就是利用这些细微的差别来对文本进行分析，从而预测出文本作者的国籍。

项目解决方案：
首先会有一个训练集(即大量的已经知道作者国籍的文本)，然后根据我们制定的规则进行训练，在这个project中我们使用的规则是：字母和字母的出现频率，单词和单词的出现频率，短语和短语的出现频率。通过训练们可以得到数据词典。在预测一段文本的时候通过在数据词典查询此文本的单词，字母和短语来预测这个文本的作者的国籍。

项目结果：
因为在项目中我们可以通过命令行选择训练规则(即我们可以选择只通过单词，只通过字母或者只通过短语，也可以是这些的结合体)，根据不同的训练规则，我们得到的最好的结果是可以正确预测出75%的文本的作者的国籍

项目分析：
这个项目是用java写的，所以对于有些规则时间复杂度特别高，后来我们发现用python写会好很多，所以项目应该用python来写，这样可以节省很多大矩阵运算的时间。并且根据我们的结果，并不是使用的规则越多，得到的结果就越准确。当我们只是用单词和字母时候，得到的数据是最准确的。其实仍然有很多规则可以用在训练算法中，例如地名，标点，语法错误等，如果我们运用了足够多的规则，理论上预测的精确程度可以到85%左右。因为没有足够的时间，所以我们没有完成这些。
项目架构：




从上面的架构可以看出这个project大致由以下三部分构成：
1．	预测文本所对应的特征表
2．	数据字典
3．	预测结果

而特征表示根据数据字典来分析文本得到的，所以这个project的关键在于数据字典的构造。首先数据字典是一个训练的结果。训练过程如下：
1．	确定特征
2．	遍历所有的训练文本，填入在该特征下语言是某一种语言的概率
3．	对数据字典进行优化，即把所有语言几乎相等的特征删掉

所以这个project预测的准确率很大程度上取决于特征的选取。这里只是简单的把所有的词当做特征，最后减掉没用的特征就得到了数据字典。其实我觉得关于特征值的选取还可以从以下几个方面考虑：
1．	不同词性的数量，例如形容词，，副词。。。
2．	表示高兴难过等感情色彩的词
3．	标点的使用
4．	俚语等特定表达的使用

其实可以挖掘的特征还有很多，可以根据不同的项目来挖掘不同的特征。这里还想说一下词分量。如果项目只用string等来直接表示词，那么这个项目的空间复杂度和时间复杂度是非常大的，而且非常不容易计算。所以必须用词分量来表示词。也就是说用一个向量来表示词，例如【0 0 0 0 0 0 0 0 1 】代表“am”，【0 0 0 0 0 0 0 0 1 1 】代表“i”。这样就可以对词进行运算。观察词分量发现：其实一个词的词分量大部分都是0，只有少数几位是1。所以我们只需要用一个数组记下来一个词的词分量那几位是1就好了。当然还有一种更简单的方法，我用一个int来代表一个词，没遇到一个新词就给他+1。当然这俩种表示都是有缺点的。假如我们只将每个词出现与否和出现的频率，几个连续的词出现与否和出现的频率进行统计，那么这种方法完全可以。但是如果我们想统计 “表示高兴难过等感情色彩的词 ” 这个特征，那么我们用这样的词分量是实现不了的。也就是说使用这样的词分量，是无法对词于词之间的关系进行刻画的。例如“高兴”和“快乐”这俩个词非常一样，那么他们的词分量也应该非常接近，遗憾的是上面表示词分量的方法是做不到这一点的。

所以如果想对词进行分类，那么可以用word2Dev这种算法来构建词分量，通过这种算法构建词分量，如果词与词之间有关系，那么他的词分量也大概率的存在某种关系，所以通过这种方法可以实现词分量之间的计算和统计。
